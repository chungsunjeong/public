{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from collections import namedtuple\n",
    "import json\n",
    "import numpy as np\n",
    "from read_data import read_data\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d='D:/Wisdom/git/tmp/BIDAF/bi-att-flow-tf1.8/data/squad/data_dev.json'\n",
    "# with open(d,'r') as json_file:\n",
    "#     data = json.load(json_file)\n",
    "# d='D:/Wisdom/git/tmp/BIDAF/bi-att-flow-tf1.8/data/squad/shared_dev.json'\n",
    "# with open(d,'r') as json_file:\n",
    "#     shared = json.load(json_file)\n",
    "config=namedtuple('config',[])\n",
    "config.data_dir='D:/Wisdom/git/tmp/BIDAF/bi-att-flow-tf1.8/data/squad/'\n",
    "config.out_dir=config.data_dir+'/out/00/'\n",
    "config.shared_path='D:/Wisdom/git/tmp/BIDAF/bi-att-flow-tf1.8/data/squad/shared_test.json'\n",
    "config.lower_word=True\n",
    "config.finetune=False\n",
    "config.known_if_glove=True\n",
    "config.use_glove_for_unk=True\n",
    "config.word_count_th=10\n",
    "config.char_count_th=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, M, JX, JQ, VW, VC, d, W,dc, dw, dco ='batch_size','max_num_sents','max_sent_size','max_ques_size',\\\n",
    "'word_vocab_size','char_vocab_size','hidden_size','max_word_size','char_emb_size','word_emb_size','char_out_size'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10570/10570 examples from dev\n"
     ]
    }
   ],
   "source": [
    "config.char_count_th=50\n",
    "dataset=read_data(config=config,data_type='dev',ref=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'char_out_size'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reset point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size=5\n",
    "\n",
    "max_word_size=16\n",
    "word_emb_size=100\n",
    "\n",
    "word_vocab_size=1223\n",
    "\n",
    "x = tf.placeholder('int32', [batch_size, None], name='x')\n",
    "cx = tf.placeholder('int32', [batch_size, None, max_word_size], name='cx')\n",
    "x_mask = tf.placeholder('bool', [batch_size, None], name='x_mask')\n",
    "q = tf.placeholder('int32', [batch_size, None], name='q')\n",
    "cq = tf.placeholder('int32', [batch_size, None, max_word_size], name='cq')\n",
    "q_mask = tf.placeholder('bool', [batch_size, None], name='q_mask')\n",
    "y = tf.placeholder('bool', [batch_size, None], name='y')\n",
    "y2 = tf.placeholder('bool', [batch_size, None], name='y2')\n",
    "is_train = tf.placeholder('bool', [], name='is_train')\n",
    "new_emb_mat = tf.placeholder('float', [None, word_emb_size], name='new_emb_mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_vocab_size=len(dataset.shared['char2idx'])\n",
    "char_emb_size=8\n",
    "char_emb_mat=tf.get_variable(\"char_emb_mat\",shape=[char_vocab_size, char_emb_size],dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(107), Dimension(8)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_emb_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.nn import embedding_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = batch_size\n",
    "# M = max_num_sents\n",
    "max_num_sents=1\n",
    "# JX = max_sent_size\n",
    "max_sent_size=618\n",
    "#  W = max_word_size\n",
    "max_word_size=26\n",
    "# dc = char_emb_size\n",
    "# JQ = max_ques_size\n",
    "max_ques_size= 33\n",
    "Acx = tf.nn.embedding_lookup(char_emb_mat,cx)  # [N, M, JX, W, dc]\n",
    "Acq = tf.nn.embedding_lookup(char_emb_mat,cq)  # [N, JQ, W, dc]\n",
    "# Acx = tf.reshape(Acx, [-1, JX, W, dc])\n",
    "# Acq = tf.reshape(Acq, [-1, JQ, W, dc])\n",
    "Acx = tf.reshape(Acx, [-1, max_sent_size, max_word_size, char_emb_size])\n",
    "Acq = tf.reshape(Acq, [-1, max_ques_size, max_word_size, char_emb_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 618, 26, 8)\n",
      "(?, 33, 26, 8)\n"
     ]
    }
   ],
   "source": [
    "print(Acx.shape)\n",
    "print(Acq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dimension(8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Acx.get_shape()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.nn import conv1d, conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### charCNN #######\n",
    "n_channel=8 #Acx.get_shape()[-1] # char_emb_size\n",
    "filter_size=100\n",
    "height=5\n",
    "char_out_size=100\n",
    "with tf.variable_scope(\"char\"):\n",
    "    filter_ = tf.get_variable('filter',shape=[1, height, n_channel, filter_size], dtype='float')\n",
    "    bias_ = tf.get_variable('bias',shape=[filter_size], dtype='float')\n",
    "    strides = [1, 1, 1, 1]\n",
    "    padding='VALID'\n",
    "    xxc = conv2d(Acx, filter_, strides, padding) + bias_  # [N*M, JX, W/filter_stride, d]\n",
    "    xx = tf.reduce_max(tf.nn.relu(xxc), 2)  # [-1, JX, d]\n",
    "    tf.get_variable_scope().reuse_variables()\n",
    "    qqc = conv2d(Acq, filter_, strides, padding) + bias_\n",
    "    qq = tf.reduce_max(tf.nn.relu(qqc), 2)  \n",
    "    xx = tf.reshape(xx, [-1, max_num_sents, max_sent_size, char_out_size])\n",
    "    qq = tf.reshape(qq, [-1, max_ques_size, char_out_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### word2vec #######\n",
    "word_emb_mat = tf.get_variable(\"word_emb_mat\", shape=[word_vocab_size, word_emb_size], dtype='float')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(100)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_emb_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb_mat = tf.concat([word_emb_mat, new_emb_mat],0)\n",
    "Ax = embedding_lookup(word_emb_mat, x) \n",
    "Aq = embedding_lookup(word_emb_mat, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, ?, 100)\n",
      "(?, 1, 400, 100)\n",
      "(5, ?, 100)\n",
      "(?, 30, 100)\n",
      "(5, ?)\n",
      "(?, 100)\n"
     ]
    }
   ],
   "source": [
    "print(Ax.shape)\n",
    "print(xx.shape)\n",
    "print(Aq.shape)\n",
    "print(qq.shape)\n",
    "print(x.shape)\n",
    "print(word_emb_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 4 but is rank 3 for 'concat_3' (op: 'ConcatV2') with input shapes: [?,1,400,100], [5,?,100], [].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\python\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1588\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1589\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1590\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Shape must be rank 4 but is rank 3 for 'concat_3' (op: 'ConcatV2') with input shapes: [?,1,400,100], [5,?,100], [].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-d62e9eafec15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# concatenation of word_vector and char_vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mxx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mqq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mqq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAq\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   1111\u001b[0m               tensor_shape.scalar())\n\u001b[0;32m   1112\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1113\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   1195\u001b[0m     \u001b[0m_attr_N\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m-> 1197\u001b[1;33m         \"ConcatV2\", values=values, axis=axis, name=name)\n\u001b[0m\u001b[0;32m   1198\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1199\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   3412\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3413\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3414\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3416\u001b[0m       \u001b[1;31m# Note: shapes are lazily computed with the C API enabled.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1754\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1755\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1756\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1757\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1758\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1590\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1591\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1592\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1594\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape must be rank 4 but is rank 3 for 'concat_3' (op: 'ConcatV2') with input shapes: [?,1,400,100], [5,?,100], []."
     ]
    }
   ],
   "source": [
    "# concatenation of word_vector and char_vector\n",
    "xx = tf.concat([xx, Ax],3)\n",
    "qq = tf.concat([qq, Aq],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "(?, 1, 400, 100)\n",
      "(?, 30, 100)\n"
     ]
    }
   ],
   "source": [
    "print(qq.get_shape()[-1])\n",
    "print(xx.shape)\n",
    "print(qq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxxx=tf.reshape(xx,[-1, 200])\n",
    "qqqq=tf.reshape(qq,[-1,200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 200)\n",
      "(150, 200)\n"
     ]
    }
   ],
   "source": [
    "print(xxxx.shape)\n",
    "print(qqqq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####### highway network #######\n",
    "# highway_num_layers=1\n",
    "# #     W_T =tf.get_variable(\"weight_transform\", shape=[d, d], dtype='float')\n",
    "# #     b_T = tf.get_variable(\"bias_transform\", shape=[d], dtype='float')\n",
    "# #     W_ = tf.get_variable(\"weight_\", shape=[d, d], dtype='float')\n",
    "# #     b_ = tf.get_variable(\"bias_\", shape=[d], dtype='float')\n",
    "#     W_T = tf.Variable(tf.truncated_normal(shp, stddev=0.1), name=\"weight_transform\")\n",
    "#     b_T = tf.Variable(tf.constant(carry_bias, shape=[d]), name=\"bias_transform\")\n",
    "\n",
    "#     W_ = tf.Variable(tf.truncated_normal(shp, stddev=0.1), name=\"weight\")\n",
    "#     b_ = tf.Variable(tf.constant(0.1, shape=[d]), name=\"bias\")\n",
    "carry_bias=0.\n",
    "with tf.variable_scope('highway'):\n",
    "    W_T = tf.Variable(tf.truncated_normal([200,200], stddev=0.1), name=\"weight_transform\")\n",
    "    b_T = tf.Variable(tf.constant(carry_bias, shape=[200]), name=\"bias_transform\")\n",
    "    W_ = tf.Variable(tf.truncated_normal([200,200], stddev=0.1), name=\"weight\")\n",
    "    b_ = tf.Variable(tf.constant(0.1, shape=[200]), name=\"bias\")\n",
    "\n",
    "    T_x = tf.sigmoid(tf.matmul(xxxx,W_T) + b_T, name=\"transform_gate\")\n",
    "    H_x = tf.nn.relu(tf.matmul(xxxx,W_) + b_, name=\"activation\")\n",
    "    C_x = tf.subtract(1.0, T_x, name=\"carry_gate\")\n",
    "    xxxx = tf.add(tf.multiply(H_x, T_x), tf.multiply(xxxx, C_x), \"highway_xx\")\n",
    "\n",
    "    tf.get_variable_scope().reuse_variables()\n",
    "    T_q = tf.sigmoid(tf.matmul(qqqq,W_T) + b_T, name=\"transform_gate\")\n",
    "    H_q = tf.nn.relu(tf.matmul(qqqq,W_) + b_, name=\"activation\")\n",
    "    C_q = tf.subtract(1.0, T_q, name=\"carry_gate\")\n",
    "    qqqq = tf.add(tf.multiply(H_q, T_q), tf.multiply(qqqq, C_q), \"highway_qq\")\n",
    "    xx=tf.reshape(xxxx,[5,400,200])\n",
    "    qq=tf.reshape(qqqq,[5,30,200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 400, 200)\n",
      "(5, 30, 200)\n"
     ]
    }
   ],
   "source": [
    "print(xx.shape)\n",
    "print(qq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.nn.rnn_cell import LSTMCell,DropoutWrapper\n",
    "from tensorflow.nn import bidirectional_dynamic_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell=LSTMCell(hidden_size)\n",
    "cell=DropoutWrapper(cell,output_keep_prob=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_len=batch_size\n",
    "q_len=batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fw_x,bw_x),_ = bidirectional_dynamic_rnn(cell,cell, xx, dtype ='float32')\n",
    "(fw_q,bw_q),_ = bidirectional_dynamic_rnn(cell,cell, qq, dtype ='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 400, 100)\n",
      "(5, 400, 100)\n"
     ]
    }
   ],
   "source": [
    "print(fw_x.shape)\n",
    "print(bw_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "h=tf.concat([fw_x,bw_x],2)\n",
    "u=tf.concat([fw_q,bw_q],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 1)\n",
      "(5, 400, 200)\n",
      "(5, 30, 200)\n"
     ]
    }
   ],
   "source": [
    "print(w_s.shape)\n",
    "print(h.shape)\n",
    "print(u.shape)\n",
    "# print(u.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 200)\n",
      "(2000, 200)\n"
     ]
    }
   ],
   "source": [
    "uu=tf.reshape(u,[-1,2*word_emb_size])\n",
    "hh=tf.reshape(h,[-1,2*word_emb_size])\n",
    "print(uu.shape)\n",
    "print(hh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 400, 30, 200)\n",
      "(5, 400, 30, 200)\n",
      "(5, 400, 30, 600)\n",
      "(60000, 600)\n"
     ]
    }
   ],
   "source": [
    "uk=tf.tile(u,[1,1,400])\n",
    "uk=tf.reshape(uk,[5,30,400,200])\n",
    "hk=tf.tile(h,[1,1,30])\n",
    "hk=tf.reshape(hk,[5,400,30,200])\n",
    "uk=tf.transpose(uk,perm=[0,2,1,3])\n",
    "print(uk.shape)\n",
    "print(hk.shape)\n",
    "element_mul=tf.multiply(uk,hk)\n",
    "element_mul.shape\n",
    "sim_mat=tf.concat([hk,uk,element_mul],3)\n",
    "print(sim_mat.shape)\n",
    "sim_mat=tf.reshape(sim_mat,[-1,600])\n",
    "print(sim_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 200)\n",
      "(60000, 200)\n"
     ]
    }
   ],
   "source": [
    "# uuu=tf.tile(uu,[30,1])\n",
    "# # uuu=tf.reshape(uuu,[2000,30,200])\n",
    "# print(uuu.shape)\n",
    "# hhh=tf.tile(hh,[400,1])\n",
    "# # hhh=tf.reshape(hhh,[150,400,200])\n",
    "# # hhh=tf.transpose(hhh,perm=[1,0,2])\n",
    "# print(hhh.shape)\n",
    "# element_mul=tf.multiply(uuu,hhh)\n",
    "# element_mul.shape\n",
    "# sim_mat=tf.concat([h,u,element_mul],2)\n",
    "# print(sim_mat.shape)\n",
    "# sim_mat=tf.reshape(sim_mat,[-1,600])\n",
    "# print(sim_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_s=tf.get_variable(\"weight_sim_mat\", shape=[6*word_emb_size,1], dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(5), Dimension(400), Dimension(30), Dimension(1)])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S=tf.matmul(sim_mat,w_s)\n",
    "S=tf.reshape(S,[batch_size,400,30,1])\n",
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.nn import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(5), Dimension(400), Dimension(30), Dimension(200)])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=softmax(S)\n",
    "a=tf.tile(a,[1,1,1,200])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 400, 30, 200)\n",
      "(5, 400, 200)\n"
     ]
    }
   ],
   "source": [
    "u_til=tf.multiply(a,uk)\n",
    "print(u_til.shape)\n",
    "u_til=tf.reduce_sum(u_til,axis=2)\n",
    "print(u_til.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 400, 200)\n",
      "Tensor(\"transpose_15:0\", shape=(5, 400, 200), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "b=softmax(tf.reduce_max(S,2))\n",
    "b=tf.tile(b,[1,1,200])\n",
    "print(b.shape)\n",
    "h_til=tf.multiply(b,h)\n",
    "h_til=tf.reduce_sum(h_til,axis=1)\n",
    "h_til=tf.tile(h_til,[1,400])\n",
    "h_til=tf.reshape(h_til,[5,200,400])\n",
    "h_til=tf.transpose(h_til,[0,2,1])\n",
    "print(h_til)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 400, 200)\n",
      "(5, 400, 200)\n",
      "(5, 400, 200)\n"
     ]
    }
   ],
   "source": [
    "print(h.shape)\n",
    "print(u_til.shape)\n",
    "print(h_til.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 400, 200)\n",
      "(5, 400, 200)\n",
      "(5, 400, 800)\n"
     ]
    }
   ],
   "source": [
    "mul_h_u_til=tf.multiply(h,u_til)\n",
    "print(mul_h_u_til.shape)\n",
    "mul_h_h_til=tf.multiply(h,h_til)\n",
    "print(mul_h_h_til.shape)\n",
    "G=tf.concat([h,u_til,mul_h_u_til,mul_h_h_til],2)\n",
    "print(G.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell2=LSTMCell(hidden_size)\n",
    "cell2=DropoutWrapper(cell2,output_keep_prob=0.7)\n",
    "(fw_G,bw_G),_ = bidirectional_dynamic_rnn(cell2,cell2, G, dtype ='float32',scope='g0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 400, 200)\n"
     ]
    }
   ],
   "source": [
    "M=tf.concat([fw_G,bw_G],2)\n",
    "print(M.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 400, 1000)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "G_M=tf.concat([G,M],2)\n",
    "print(G_M.shape)\n",
    "w_p1=tf.get_variable(\"w_p1\", shape=[10*word_emb_size], dtype='float')\n",
    "print(w_p1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 400)\n"
     ]
    }
   ],
   "source": [
    "p1=softmax(tf.tensordot(G_M,w_p1,[2,0]))\n",
    "print(p1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 400, 200)\n"
     ]
    }
   ],
   "source": [
    "cell3=LSTMCell(hidden_size)\n",
    "cell3=DropoutWrapper(cell3,output_keep_prob=0.7)\n",
    "(fw_M,bw_M),_ = bidirectional_dynamic_rnn(cell3,cell3, M, dtype ='float32',scope='M2_')\n",
    "M2=tf.concat([fw_M,bw_M],2)\n",
    "print(M2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "w_p2=tf.get_variable(\"w_p2_\", shape=[10*word_emb_size], dtype='float')\n",
    "print(w_p2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 400)\n"
     ]
    }
   ],
   "source": [
    "G_M2=tf.concat([G,M2],2)\n",
    "p2=softmax(tf.tensordot(G_M2,w_p2,[2,0]))\n",
    "print(p2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=p1)\n",
    "loss+=tf.nn.softmax_cross_entropy_with_logits(labels=y2,logits=p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add:0' shape=(5,) dtype=float32>"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
