{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8. Deep Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "층을 깊게 한 심층 신경망을 딥러닝이라 한다. 뒷단에 층을 추가할 때 커다란 문제 몇가지가 있다. 8장에서는 딥러닝의 특징과 과제, 가능성을 본다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ch08/train_deepnet.py: 훈련용 코드<br>\n",
    "ch08/deep_convnet.py: 신경망 구현 소스 코드<br>\n",
    "ch08/deep_conv_net_params.pkl: 미리 학습된 가중치 매개변수<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 구현한 신경망은 VGG신경망을 참초하였으며 층이 깊어지면서 채널 수가 더 늘어나는 것이 특징이다. 합성곱 계층의 채널 수는 앞 계층에서부터 순서대로 16,16,32,32,64,64로 늘어난다. 특징을 정리하면 다음과 같다. \n",
    "    * 3*3의 작은 필터를 사용한 합성곱 계층\n",
    "    * 활성화 함수: ReLU\n",
    "    * fully-connected layer 뒤에 드롭아웃 계층 사용\n",
    "    * Adam 을 이용해 최적화\n",
    "    * 가중치 초기값은 He initialization\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 결과 정확도는 99.38% 이다. 인식에 실패한 예를 보면 인간도 판단하기 어려운 이미지들이 많다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__정확도 향상에 도움이 될 수 있는 것들__<br>\n",
    "데이터확장, 앙상블 학습, 학습률 감소 등은 정확도 향상에 도움이 될 수 있다. 데이터 확장 (data augmentation)은 입력 이미지를 알고리즘을 동원해 인위적으로 확장한다. 입력 이미지를 회전하거나 세로로 이동하는 등 미세한 변화를 주어 이미지의 개수를 늘린다. 이는 데이터가 몇 개 없을 때 특히 효과적이다. 회전이나 이동을 통한 변형 외에 이미지 일부를 잘라내는 crop, 좌우를 뒤집는 flip 등이 있다. 일반적인 이미지에는 밝기 등의 외형 변화나 확대축소 등의 스케일 변화도 효과적이다. 쉬운 트릭일지라도 멋진 결과를 가져오는 경우가 많다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__깊게 하는 이유__<br>\n",
    "층을 깊게 하는 것이 왜 중요한가에 대한 이론적 근거는 아직 많이 부족하다. 다소 직관적인 설명은 몇 가지 있다. 대규모 이미지 인식 대회의 결과에서 상위를 차지한 기법 대부분은 딥러닝 기반이며 그 경향은 신경망을 더 깊게 만드는 방향으로 가고 있다. 층의 깊이에 비례해 정확도가 좋아지는 것이다. <br>\n",
    "층을 깊게 할 때 이점 중 하나는 신경망의 매개변수 수가 줄어든다는 것이다. 층을 깊게 한 신경망은 깊지 않은 경우보다 적은 매개변수로 같은 (혹은 그이상) 수준의 표현력을 달성할 수 있다. 예를 들면 5\\*5 합성공 연산 1회 (매개변수 25개)는 3\\*3 합성곱 연산 2회 (매개변수 18개)를 수행하여 대체할 수 있다. 매개 변수 수는 층을 반복할수록 적어지고, 그 개수의 차이는 층이 깊어질수록 커진다. 예를 들어 3\\*3 합성곱 연산 3회시 매개변수 27개인 반편 같은 크기의 영역을 1회의 합성곱 연산으로 보기 위해선 7\\*7 크기의 필터 매개변수 49개가 필요하다. <br>\n",
    "두번째 이점으로 학습의 효율성이 있다. 층을 깊게하여 학습 데이터의 양을 줄여 학습을 고속으로 수행할 수 있다. Ch7 CNN 시각화에서 합성곱 계층이 정보를 계층적으로 추출하고 있음을 보았다. 즉 층이 깊어지면서 점차 더 복잡한 것에 뉴런이 반응하였다. 따라서 얕은 신경망에서 복잡한 사물 인식 문제를 해결하려면 합성곱 계층은 복잡한 사물의 특징 대부분을 한 번에 '이해'해야한다. 따라서 이러한 특징을 이해하려면 변화가 풍부하고 많은 학습 데이터가 필요하고 결과적으로 학습 시간이 오래 걸린다. 그러나 신경망을 깊게 하면 학습 해야할 문제를 계층적으로 분해할 수 있다. 각 층이 학습해야 할 문제를 더 단순한 문제로 대체할 수 있다는 것이다. 예를 들어 처음 층은 에지 학습에 전념하여 적은 학습 데이터로 효율적으로 학숩할 수 있다. 또한, 층을 깊게 하면 정보를 계층적으로 전달할 수 있다는 점도 중요하다. 예로 엣지를 추출한 층의 다음 층은 엣지 정보를 쓸 수 있고, 더 고도의 패턴을 효과적으로 학숩하리라 기대할 수 있다. 즉, 층을 깊이 함으로써 각 층이 학습해야 할 문제를 '풀기 쉬운 단순한 문제'로 분해할 수 있어 효율적으로 학습하리라 기대할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ImageNet Large Scale Visual recognition Challenge__<br>\n",
    "ImageNet: 100만장이 넘는 이미지를 담고 있는 데이터셋. <br>\n",
    "이를 잘 분류하는 대회가 ILSVRC 이다. 여기서 AlexNet를 시작으로 CNN기반 학습방법이 계속해서 1등을 해오고 있다. 대표적으로 AlexNet, VGG, GoogLeNet, ResNet 이 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__transfer learning__<br>\n",
    "이미지넷이 제공하는 거대한 데이터셋으로 학습한 가중치 값들은 실제 제품에 활용해도 효과적이고, 실제로 많이들 그렇게 이용하고 있다. 이를 transfer learning 전이학습이라고 한다. 이는 학습된 가중치를 다른 신경망에 복사한 다음 그 상태로 재학습을 수행하는 것이다. 예를 들어 VGG와 구성이 같은 신경망을 준비하고 미리 학습된 가중치를 초깃값으로 설정한 후, 새로운 데이터셋을 대상으로 fine tuning (재학습)을 수행한다. 전이 학습은 보유한 데이터셋이 적을 때 특히 유용한 방법이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 고속화\n",
    "빅데이터와 네트워크 발전으로 딥러닝에선 대량의 연산을 수행해야한다. 과거엔 주로 CPU가 계산을 담당했으나 요즘 프레임워크 대부분은 GPU를 활용해 대량의 연산을 고속으로 처리한다. 최근 프레임워크에선 학습을 복수의 GPU와 여러 기기로 분산 수행하기 시작했다. <br><br>\n",
    "__GPU를 활용한 고속화__<br>\n",
    "GPU는 원래 그래픽 전용 보드에 이용해왔다. 그러나 최근 범용 수치 연산에도 이용한다. GPU는 병렬 수치 연산을 고속으로 처리할 수 있으니 그 압도적인 힘을 다양한 용도로 활용하자는 것이 GPU computing 의 목적이다. 이처럼 GPU로 범용 연산을 수행하는 것을 GPU 컴퓨팅이라고 한다. 딥러닝에선 대량의 __단일 곱셈 누산__ 을 수행해야한다. 이러한 대량 병렬 연산은 GPU의 특기다. 반대로 CPU는 연속적인 복잡한 계산을 잘 처리한다. 딥러닝 연산에는 GPU를 이용하면 CPU만 쓸 때보다 놀라울 정도로 빠르게 결과를 얻을 수 있다. 또한 딥러닝에 최적화된 라이브러리를 이용하면 더더욱 빨라지게 된다. <br>\n",
    "GPU는 주로 엔비디아 AMD 두 회사가 제공하지만 대부분의 딥러닝 프레임워크는 엔비디아 GPU에서만 혜택을 받을 수 있다. 이는 __CUDA__ 라는 엔비디아 GPU 컴퓨팅용 통합 개발 환경을 사용하기 때문이다. cuDNN은 CUDA 위에서 동작하는 딥러닝 라이브러리로 딥러닝에 최적화된 함수 등이 구현돼 있다. <br><br>\n",
    "__분산학습__<br>\n",
    "GPU로 딥러닝 연산을 꽤 가속할 수 있지만 1회 학습에 걸리는 시간을 최대한 단축하고자 분산 학습 개념이 중요해졌다. 이는 딥러닝 학습을 scale out (수평 확장) 하자는 아이디어이다. 딥러닝 게산을 더욱 고속화 하고자 다수의 GPU와 기기로 계산을 분산한다. 최근 다수의 GPU와 컴퓨터를 이용한 분산 학습을 지원한 딥러닝 프레임워크들이 나타나고 있다. 그중 구글의 텐서플로와 마이크로소프트의 CNTK는 분산 학습에 역점을 두고 개발중이다. 거대한 데이터센터의 low latency, high throughput (저지연 고처리량) 네트워크 위에서 이들 프레임워크가 수행하는 분산 학습은 놀라운 효과를 보이고 있다. 분산학습에서 계싼을 어떻게 분산시키느냐는 몹시 어려운 문제이다. 이런 문제는 텐서플로 같은 뛰어난 프레임워크에 맡기는 것이 좋다. <br><br>\n",
    "__연산 정밀도와 비트 줄이기__<br>\n",
    "계산 능력 외에 메모리 용량과 버스 대역폭 등이 딥러닝 고속화에 병목이 될 수 있다. 메모리 용량 면에선 대량의 가중치 매개변수와 중간 데이터를 메모리에 저장해야한다는 것을 생각해야한다. 버스 대역폭 면에선 GPU(or CPU)의 버스를 흐르는 데이터가 많아져 한계를 넘어서면 병목이 된다. 이런 경우를 고려하면 네트워크로 주고받는 데이터의 비트수는 최소로 만드는 것이 바람직하다. <br>\n",
    "컴퓨터에선 주로 64비트나 32비트 부동소수점 수를 사용해 실수를 표현한다. 많은 비트를 사용할수록 계산 오차는 줄어들지만 그만큼 계산 비용과 메모리 사용량이 늘고 버스 대역폭에 부담을 준다. 다행히 딥러닝은 높은 수치 정밀도를 요구하지 않는다. 이는 신경망의 중요한 성질 중 하나로 신경망의 견고성에 따른 특성이다. 예로 신경망은 입력 이미지에 노이즈가 조금 섞여 있어도 출력 결과가 잘 달라지지 않는 강건함을 보인다. 이런 견고성 덕분에 신경망을 흐르는 데이터를 퇴화시켜도 출력에 주는 영향은 적다. <br>\n",
    "컴퓨터에서 실수를 표현하는 방식으로 32비트 단정밀도(single-precision)와 64비트 배정밀도(double-precision) 부동소수점 등의 포맷이 있지만 지금까지의 실험으로는 딥러닝은 16비트 반정밀도(half-precision) 만 사용해도 학습에 문제가 없다 알려져 있다. 실제로 엔비디아의 최신 GPU인 파스칼 아키텍처는 이 포맷을 지원하여 이제는 반정밀도 부동소수점이 표준적으로 이용되리라 생각이 된다. <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 활용\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝은 사물 인식 뿐 아니라 이미지,음성,자연어 등 수많은 분야에서 뛰어난 성능을 발휘한다. <br>\n",
    "1. 사물검출: 이미지 속에 담긴 사물의 위치와 종류를 알아낸다. 사물 인식보다 어렵다. Regions with CNN이 유명하다. R-CNN에서 후보 영역 추출과 CNN 특징 계산이 포인트이다. \n",
    "2. 분할(segmentation): 이미지를 픽셀 수준에서 분류하는 문제. 추론할 때 입력 이미지의 모든 픽셀을 분류한다. 신경망을 이용해 분할하는 가장 단순한 방법은 모든 픽셀 각각을 추론하는 것이다. 이 때 픽셀 수만큼 forward 처리가 길어져 fully convolutional network 방법이 고안되었다. 이는 단 한번의 forward 처리로 모든 픽셀의 클래스를 분류해준다. 이는 합성곱 계층으로만 구성된 네트워크이다. 완전연결 계층을 같은 기능을 하는 합성곱 계층으로 대체했다. \n",
    "3. 사진 캡션 생성: 사진이 주어지면 사진을 설명하는 글을 자동으로 생성하는 연구이다. 딥러닝 기반 방법으로는 neural image caption 모델이 대표적이다. 이는 심층 CNN와 RNN으로 구성된다. RNN은 순환적 관계를 갖는 신경망으로 자연어나 시계열 데이터 등의 연속된 데이터를 다룰 때 많이 사용된다. NIC는 CNN으로 사진의 특징을 추출하고 그 특징은 RNN에 넘긴다. RNN은 CNN이 추출한 특징을 초깃값으로 해서 텍스트를 순환적으로 생성한다. 사진이나 자연어와 같은 여러 종류의 정보를 조합하고 처리하는 것을 multimodal processing 이라고 한다. \n",
    "4. 이미지 생성: deep convolutional generative adversarial network 기법을 사용하여 아무것도 없는 무로부터 특정 이미지를 생성하는게 가능하다. 학습시에는 대량의 이미지를 사용하지만 학습이 끝난후에는 아무런 입력 없이도 새로운 그림을 그릴 수 있다. DCGAN은 이미지를 생성하는 과정을 모델화한다. 그 모델을 대량의 이미지를 사용해 학습하고 학습이 끝나면 그 모델을 이용하여 새로운 그림을 생성할 수 있다. DCGAN 기술의 핵심은 generator 와 discriminator 로 불리는 2개의 신경망을 이용한다는 점이다. 생성자가 진짜와 똑같은 이미지를 생성하고 식별자는 그것이 진짜인지 (생성자가 생성한 이미지인지, 아니면 실제로 촬영된 이미지인지)를 판정한다. 그렇게해서 둘을 겨루도록 학습시켜 생성자는 더 정교한 가까 이미지 생성 기술을 학습하고, 식별자는 더 정확하게 간파할 수 있는 감정사로 성장하게 된다. 이렇게 둘의 능력을 부지런히 갈고닦게 한다는 개념이 GAN 기술의 재미난 점이다. 그렇게 성장한 생성자는 최종적으로 진짜와 착각할 정도의 이미지를 그려내는 능력을 기른다. \n",
    "5. 자율 주행: 다양한 환경에서도 안전한 주행 영역을 올바로 인식해야한다. 이런 인식 기술에서 딥러닝이 큰 역할을 해줄 것으로 기대한다. 그 예로 SegNet 이라는 CNN 기반 신경망은 주변환경을 정확하게 인식해낸다. 입력 이미지를 픽셀 수준에서 판정하며 결과를 보면 도로 건물 보도 나무 차량 오토바이 등을 어느정도 정확히 판별한다. \n",
    "6. 강화 학습: Deep Q-network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Chapter 8 정리\n",
    "    * 수많은 문제에서 신경망을 더 깊게 하여 성능을 개선할 수 있다.\n",
    "    * 유명한 신경망: VGG, GoogLeNet, ResNet\n",
    "    * GPU, 분산 학습, 비트 정밀도 감소 등으로 딥러닝을 고속화 할 수 있다.\n",
    "    * 딥러닝은 사물 인식, 사물 검출, 분할, 사진 캡션 생성, 이미지 생성, 강화학습 등에도 사용될 수 있다.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
