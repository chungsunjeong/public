{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pos_label = set()\n",
    "\n",
    "# i = 0\n",
    "# pos_sample=pd.DataFrame()\n",
    "# for drug, targets in dict_DTI.items():\n",
    "#     for target in targets:\n",
    "#         pair_name=[str(drug) + '_' + target]\n",
    "#         pos_label.update(pair_name)\n",
    "#         if i==0:\n",
    "#             pos_sample=pd.DataFrame(pd.concat([matrix_drug.loc[drug],matrix_target.loc[target]]),columns=pair_name)\n",
    "#         else:\n",
    "#             spl=pd.DataFrame(pd.concat([matrix_drug.loc[drug],matrix_target.loc[target]]),columns=pair_name)\n",
    "#             pos_sample=pos_sample.join(spl)\n",
    "#         i+=1\n",
    "# '--------------------------------------'\n",
    "# pos_sample = pos_sample.T\n",
    "# print(pos_sample.shape)\n",
    "# print('# of positive samples: ' + str(len(pos_label)))\n",
    "# n_positive = len(pos_label)\n",
    "# n_negative = n_positive\n",
    "# neg_label_total = set()\n",
    "# for ind1 in matrix_target.index:\n",
    "#     for ind2 in matrix_drug.index:\n",
    "#         neg_label_total.update([str(ind2) + '_' + str(ind1)])\n",
    "# print(len(neg_label_total))\n",
    "# neg_label_total = neg_label_total.difference(pos_label)\n",
    "# neg_label = np.random.choice(list(neg_label_total), size=n_negative, replace=False)\n",
    "# '--------------------------------------'\n",
    "# pos_label = set()\n",
    "\n",
    "# for drug, targets in dict_DTI.items():\n",
    "#     for target in targets:\n",
    "#         pair_name = [str(drug) + '_' + target]\n",
    "#         pos_label.update(pair_name)\n",
    "# print(pos_label)\n",
    "# '--------------------------------------'\n",
    "\n",
    "\n",
    "# neg_sample=pd.DataFrame()\n",
    "# j=0\n",
    "# # dtype_drug=np.issubdtype(matrix_drug.index.dtype,np.number)\n",
    "# # dtype_target=np.issubdtype(matrix_target.index.dtype,np.number)\n",
    "# for neg in neg_label:\n",
    "#     drug, target = neg.split('_',1)\n",
    "#     if j==0:\n",
    "#         neg_sample = pd.DataFrame(pd.concat([matrix_drug.loc[drug], matrix_target.loc[target]]),\n",
    "#                                       columns=[neg])\n",
    "#     else:\n",
    "#         df_tmp = pd.DataFrame(pd.concat([matrix_drug.loc[drug], matrix_target.loc[target]]), columns=[neg])\n",
    "#         neg_sample = neg_sample.join(df_tmp)\n",
    "#     j += 1\n",
    "# neg_sample = neg_sample.T\n",
    "# print(neg_sample.shape)\n",
    "# neg_sample.to_csv('neg_sample.txt',sep='\\t')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "def doublewrap(function):\n",
    "    \"\"\"\n",
    "    A decorator decorator, allowing to use the decorator to be used without\n",
    "    parentheses if no arguments are provided. All arguments must be optional.\n",
    "    \"\"\"\n",
    "    @functools.wraps(function)\n",
    "    def decorator(*args, **kwargs):\n",
    "        if len(args) == 1 and len(kwargs) == 0 and callable(args[0]):\n",
    "            return function(args[0])\n",
    "        else:\n",
    "            return lambda wrapee: function(wrapee, *args, **kwargs)\n",
    "    return decorator\n",
    "\n",
    "\n",
    "@doublewrap\n",
    "def define_scope(function, scope=None, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    A decorator for functions that define TensorFlow operations. The wrapped\n",
    "    function will only be executed once. Subsequent calls to it will directly\n",
    "    return the result so that operations are added to the graph only once.\n",
    "    The operations added by the function live within a tf.variable_scope(). If\n",
    "    this decorator is used with arguments, they will be forwarded to the\n",
    "    variable scope. The scope name defaults to the name of the wrapped\n",
    "    function.\n",
    "    \"\"\"\n",
    "    attribute = '_cache_' + function.__name__\n",
    "    name = scope or function.__name__\n",
    "    @property\n",
    "    @functools.wraps(function)\n",
    "    def decorator(self):\n",
    "        if not hasattr(self, attribute):\n",
    "            with tf.variable_scope(name, *args, **kwargs):\n",
    "                setattr(self, attribute, function(self))\n",
    "        return getattr(self, attribute)\n",
    "    return decorator\n",
    "\n",
    "\n",
    "class SoftmaxClassifier:\n",
    "    def __init__(self,x,y,DTI):\n",
    "        self.n_class = 2\n",
    "        self.feature_size=DTI.train.data.shape[1]\n",
    "        self.n_train=DTI.train.data.shape[0]\n",
    "        self.n_test=DTI.test.data.shape[0]\n",
    "        self.x=x\n",
    "        self.y=y\n",
    "        self.prediction\n",
    "        self.optimize\n",
    "        self.accuracy\n",
    "        self.cost\n",
    "        \n",
    "    @define_scope(initializer=tf.contrib.slim.xavier_initializer())\n",
    "    def prediction(self):\n",
    "        x=self.x\n",
    "        W = tf.Variable(tf.zeros([self.feature_size, self.n_class]), name='W')\n",
    "        b = tf.Variable(tf.zeros([self.n_class]), name='b')\n",
    "        return tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "    \n",
    "    @define_scope\n",
    "    def cost(self):\n",
    "        return tf.reduce_mean(-tf.reduce_sum(y * tf.log(self.prediction+1e-12), reduction_indices=[1]))    \n",
    "    \n",
    "    @define_scope\n",
    "    def optimize(self):\n",
    "        return tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(self.cost)   \n",
    "    @define_scope\n",
    "    def accuracy(self):\n",
    "        correct_prediction = tf.equal(tf.argmax(self.prediction, 1), tf.argmax(self.y, 1))\n",
    "        return tf.reduce_mean(tf.cast(correct_prediction, dtype='float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "lr = 0.01\n",
    "n_class = 2\n",
    "feature_size=DTI.train.data.shape[1]\n",
    "n_train=DTI.train.data.shape[0]\n",
    "n_test=DTI.test.data.shape[0]\n",
    "batch_size = 1000\n",
    "training_iteration = 100\n",
    "\n",
    "avg_cost_list = []\n",
    "epoch = int(training_iteration * batch_size / DTI.train.data.shape[0])\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, feature_size])\n",
    "W = tf.Variable(tf.zeros([feature_size, n_class]), name='W')\n",
    "b = tf.Variable(tf.zeros([n_class]), name='b')\n",
    "prediction= tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "y = tf.placeholder(tf.float32, [None, n_class])\n",
    "\n",
    "cost=tf.reduce_mean(-tf.reduce_sum(y * tf.log(prediction+1e-12), reduction_indices=[1]))   \n",
    "optimize= tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)   \n",
    "# classifier=SoftmaxClassifier(x,y,DTI)\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class roc_auc(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.aucs = []\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.validation_data[0])\n",
    "        self.aucs.append(roc_auc_score(self.validation_data[1], y_pred))\n",
    "        if max(self.aucs) == self.aucs[-1]:\n",
    "            model.save_weights(\"weights.roc_auc.hdf5\")\n",
    "        print(\" - auc: %0.4f\" % self.aucs[-1])\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
