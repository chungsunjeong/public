{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "import matplotlib.pyplot as plt\n",
    "from model import keras_models\n",
    "from module_DTI import my_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of drug: 1862\n",
      "# of target: 1554\n",
      "\n",
      "# of drugs: 1862\n",
      "# of features of a drug: 881\n",
      "\n",
      "# of targets: 1554\n",
      "# of features of a target: 876\n",
      "\n",
      "# of drug-target interactions: 4809\n",
      "\n",
      "Load existing positive & negative sample files.\n",
      "# of positive samples: 4809\n",
      "# of features of a positive sample: 1757\n",
      "\n",
      "# of negative samples: 4809\n",
      "# of features of a negative sample: 1757\n",
      "\n",
      "epoch:\t5\n"
     ]
    }
   ],
   "source": [
    "dict_directories = {'dir_ROOT': 'C:\\\\Users\\\\csjeong\\\\Desktop\\\\research\\\\dataset\\\\conv_DTI\\\\2012, Tabei', }\n",
    "dict_directories.update({\n",
    "    'DTI_adjmat' : dict_directories['dir_ROOT'] + '\\\\inter_admat.txt',\n",
    "    'drug' : dict_directories['dir_ROOT'] + '\\\\drug_repmat.txt',\n",
    "    'target' : dict_directories['dir_ROOT']+ '\\\\target_repmat.txt'\n",
    "})\n",
    "DTI=my_dataset.DTI_Dataset(dict_directories)\n",
    "DTI.load_data()\n",
    "DTI.load_pos_neg_samples(neg_to_pos_ratio=1)\n",
    "DTI.split_train_test_set(split_ratio=0.99)\n",
    "\n",
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "n_class = 2\n",
    "feature_size = DTI.train.data.shape[1]\n",
    "n_train = DTI.train.data.shape[0]\n",
    "n_test = DTI.test.data.shape[0]\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "training_iteration = 2000\n",
    "\n",
    "avg_cost_list = []\n",
    "train_x, train_y = DTI.train.next_batch(batch_size=n_train, pos_neg_label=DTI.pos_neg_label)\n",
    "test_x, test_y = DTI.test.next_batch(DTI.test.data.shape[0], DTI.pos_neg_label, one_hot_encoding=True)\n",
    "print('epoch:\\t' + str(epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConfig(object):\n",
    "    learning_rate = 0.001\n",
    "    batch_size = 100\n",
    "    training_iteration = 200\n",
    "    epoch = int(training_iteration * batch_size / DTI.train.data.shape[0])\n",
    "    keep_prob=1.0\n",
    "    feature_size=1757\n",
    "    n_class=2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6530612\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "class MyTensorflow(object):\n",
    "    def __init__(self, session, config, is_training=False):\n",
    "        self.config=config\n",
    "        self._session = session\n",
    "        self._batch_size = config.batch_size\n",
    "        self._training_iteration = config.training_iteration\n",
    "        self._learning_rate = config.learning_rate\n",
    "        self._input_size = [None, config.feature_size]\n",
    "        self._output_size = [None, config.n_class]\n",
    "           \n",
    "    def train(self, DTI):\n",
    "        avg_cost = 0.\n",
    "        batch_xs, batch_ys = DTI.train.next_batch(self._batch_size, DTI.pos_neg_label)\n",
    "        self._session.run(self._optimize, feed_dict={self._x: batch_xs, self._y: batch_ys})\n",
    "        avg_cost += self._session.run(self._loss, feed_dict={self._x: batch_xs, self._y: batch_ys}) / self._batch_size\n",
    "        return avg_cost\n",
    "\n",
    "    def get_accuracy(self, DTI):\n",
    "        test_x, test_y = DTI.test.next_batch(DTI.test.data.shape[0], DTI.pos_neg_label, one_hot_encoding=True)\n",
    "        ac = self._session.run(self._accuracy, feed_dict={self._x: test_x, self._y: test_y})\n",
    "        return ac\n",
    "     \n",
    "class mymodel(MyTensorflow):\n",
    "    def __init__(self, session, config, is_training=False):\n",
    "        super(mymodel,self).__init__(session,config,is_training)\n",
    "        self.build_graph()\n",
    "        \n",
    "    def loss(self,true_logits, predicted_logits):\n",
    "        return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=predicted_logits, labels=true_logits))\n",
    "    \n",
    "    def optimize(self,loss, optimizer=tf.train.AdamOptimizer()):\n",
    "        optimizer.learning_rate=self._learning_rate\n",
    "        return optimizer.minimize(loss)\n",
    "    \n",
    "    def build_graph(self):\n",
    "        x = tf.placeholder(tf.float32, self._input_size)\n",
    "        y = tf.placeholder(tf.float32, self._output_size)\n",
    "        W = tf.Variable(tf.zeros([self.config.feature_size, self.config.n_class]), name='W')\n",
    "        b = tf.Variable(tf.zeros([n_class]), name='b')\n",
    "        y_pred = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "        \n",
    "        _loss = self.loss(y,y_pred)\n",
    "        _optimize=self.optimize(_loss,optimizer=tf.train.AdamOptimizer())\n",
    "        \n",
    "\n",
    "        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_pred, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, dtype='float32'))\n",
    "    \n",
    "        self._x=x\n",
    "        self._y=y\n",
    "        self._W=W\n",
    "        self._b=b\n",
    "        self._y_pred=y_pred\n",
    "        self._loss=_loss\n",
    "        self._optimize=_optimize\n",
    "        self._correct_prediction=correct_prediction\n",
    "        self._accuracy=accuracy\n",
    "        tf.global_variables_initializer().run()\n",
    "        self.saver=tf.train.Saver()\n",
    "\n",
    "\n",
    "my_config = MyConfig()\n",
    "with tf.Graph().as_default(), tf.Session() as session:\n",
    "    m = mymodel(session, my_config)\n",
    "    for _ in range(my_config.training_iteration):\n",
    "        avg_cost = m.train(DTI)\n",
    "    #     print(avg_cost)\n",
    "    print(m.get_accuracy(DTI))\n",
    "    print(my_config.epoch)\n",
    "    m.saver.save(session,\n",
    "                    os.path.join('./saved_model', \"tf_model_test.ckpt\"))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 20\n",
    "total_data=3000\n",
    "\n",
    "batch_size=100\n",
    "iteration=600\n",
    "\n",
    "batch_size=101\n",
    "iteration=594 + 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
