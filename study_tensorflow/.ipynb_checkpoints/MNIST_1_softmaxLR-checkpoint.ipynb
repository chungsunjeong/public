{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# [T3] MNIST classification with softmax logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "55000\n",
      "5000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "mnist=input_data.read_data_sets(\"MNIST_data/\",one_hot=True)\n",
    "print(mnist.train.num_examples)\n",
    "print(mnist.validation.num_examples)\n",
    "print(mnist.test.num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter and hyperparameter setting\n",
    "pixel=28\n",
    "image_size=pixel*pixel\n",
    "n_class=10\n",
    "\n",
    "lr=0.5\n",
    "training_epochs=100\n",
    "batch_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.placeholder(tf.float32,[None,image_size])\n",
    "W=tf.Variable(tf.zeros([image_size,n_class]),name='W')\n",
    "b=tf.Variable(tf.zeros([n_class]),name='b')\n",
    "y=tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "y_=tf.placeholder(tf.float32,[None,n_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'W:0' shape=(784, 10) dtype=float32_ref>, <tf.Variable 'b:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'W_1:0' shape=(784, 10) dtype=float32_ref>, <tf.Variable 'b_1:0' shape=(10,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "print(tf.trainable_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "name: \"GradientDescent\"\n",
      "op: \"NoOp\"\n",
      "input: \"^GradientDescent/update_W/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_b/ApplyGradientDescent\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cost=tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y),reduction_indices=[1]))\n",
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate=lr).minimize(cost)\n",
    "# accuracy_train=tf.reduce_mean(tf.cast(tf.equal(tf.argmax(y,1),tf.argmax(y_,1)),tf.float32))\n",
    "\n",
    "print(cost)\n",
    "print(optimizer)\n",
    "sess=tf.Session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 784)\n",
      "(100, 10)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "batch_xs,batch_ys=mnist.train.next_batch(100)\n",
    "print(batch_xs.shape)\n",
    "print(batch_ys.shape)\n",
    "print(type(batch_xs))\n",
    "print(type(batch_ys))\n",
    "# print(batch_xs[0,:])\n",
    "# print(batch_ys[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init=tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "avg_cost_list=[]\n",
    "total_batch=int(mnist.train.num_examples/batch_size)\n",
    "for epoch in range(training_epochs):\n",
    "    # accuracy_list=[]\n",
    "    avg_cost=0.\n",
    "    \n",
    "    for step in range(total_batch):\n",
    "        batch_xs,batch_ys=mnist.train.next_batch(batch_size)\n",
    "        sess.run(optimizer,feed_dict={x:batch_xs,y_:batch_ys})\n",
    "        avg_cost+=sess.run(cost,feed_dict={x:batch_xs,y_:batch_ys})/total_batch\n",
    "    avg_cost_list.append(avg_cost)\n",
    "plt.plot(range(training_epochs),avg_cost_list)\n",
    "# show training accuracy as iteraction in one epoch\n",
    "#         accuracy_list.append(sess.run(accuracy_train,feed_dict={x:batch_xs,y_:batch_ys}))\n",
    "# itr=range(total_batch)\n",
    "# acc=accuracy_list\n",
    "# plt.plot(itr,acc)\n",
    "# plt.xlabel('iteraction')\n",
    "# plt.ylabel('training accuracy')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,dtype='float32'))\n",
    "ac=sess.run(accuracy,feed_dict={x:mnist.test.images, y_:mnist.test.labels})\n",
    "print(str(ac*100)+'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
